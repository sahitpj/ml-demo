# Interactive Gradient Optimizers

The following is a demo for ADAM and ADAGRAD gradient optimizers. 

### Instructions to use:

Simply vist the following site :- https://sahitpj.github.io/ml-demo/ and click anywhere on the SVG to look at how gradient optimization works. Use the slider to change the learning rate. The optimizers can be selcted or deselcted using the buttons below. 

Although the contour function cannot be changed interactively. The option to change can be done, by changing the source code of the `.html` page. in the **function f(x, y)** area.  

Would like to thank EmilienDupont for the starter code. 